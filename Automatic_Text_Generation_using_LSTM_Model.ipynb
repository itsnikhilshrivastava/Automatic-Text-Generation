{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic Text Generation using LSTM Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZkMXhro1Odd-",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eeTy6b1MOsu7",
        "colab": {}
      },
      "source": [
        "response = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mvE3MshkOwtU",
        "colab": {}
      },
      "source": [
        "response.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RGw4xSpOOzHX",
        "colab": {}
      },
      "source": [
        "data = response.text.split('\\n')\n",
        "data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REmRA5dUO1UL",
        "colab": {}
      },
      "source": [
        "data = data[253:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YSG20DE-UUNH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb35ff27-389d-47ae-c588-d8563d0b0e63"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  From fairest creatures we desire increase,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kYyJqbAbUUVM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ca588ef-0f4c-466f-84e5-ed7141ef2914"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SIEMel6ZUUbl",
        "colab": {}
      },
      "source": [
        "data = ' '.join(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_NdKbrUFUUhh",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HTF1tfq6UUme",
        "colab": {}
      },
      "source": [
        "def clean_text(doc):\n",
        "    tokens = doc.split()\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    tokens = [w.translate(table) for w in tokens]\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OYlzRLNwUUrr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "03da67d0-c5f7-4ff5-caac-a3a7a09587a6"
      },
      "source": [
        "tokens = clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['from', 'fairest', 'creatures', 'we', 'desire', 'increase', 'that', 'thereby', 'beautys', 'rose', 'might', 'never', 'die', 'but', 'as', 'the', 'riper', 'should', 'by', 'time', 'decease', 'his', 'tender', 'heir', 'might', 'bear', 'his', 'memory', 'but', 'thou', 'contracted', 'to', 'thine', 'own', 'bright', 'eyes', 'feedst', 'thy', 'lights', 'flame', 'with', 'selfsubstantial', 'fuel', 'making', 'a', 'famine', 'where', 'abundance', 'lies', 'thy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2rGoab1pUUzc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "449c91a5-99b7-4799-aa39-3cacfc6f27ac"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "898199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EhmttkM7Ujc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27672202-9e19-46f8-d517-86b2604b78a3"
      },
      "source": [
        "len(set(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eFSvvukSUjiz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cffce4a-1f0d-458a-b68a-b274500ac804"
      },
      "source": [
        "length = 50 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "    seq = tokens[i-length:i]\n",
        "    line = ' '.join(seq)\n",
        "    lines.append(line)\n",
        "    if i > 200000:\n",
        "        break\n",
        "        \n",
        "print(len(lines))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cTgP4bdJUjpZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a7de1de1-37d4-44b8-d468-8d788a5e8983"
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from fairest creatures we desire increase that thereby beautys rose might never die but as the riper should by time decease his tender heir might bear his memory but thou contracted to thine own bright eyes feedst thy lights flame with selfsubstantial fuel making a famine where abundance lies thy self'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MXKaKJb1UjuU",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cuyRsMIVUjxy",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SrUiNdc7UtnQ"
      },
      "source": [
        "Build LSTM Model and Prepare x and y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "78tckF4oUwst",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ahX_RkffUwwx",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3yYWcSUeUwzv",
        "colab": {}
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "x, y = sequences[:, :-1], sequences[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hf7ENRx9Uw59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "df50a4e1-adfe-46c5-ec78-a8076698ad09"
      },
      "source": [
        "x[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   47,  1408,  1264,    37,   451,  1406,     9,  2766,  1158,\n",
              "        1213,   171,   132,   269,    20,    24,     1,  4782,    87,\n",
              "          30,    98,  4781,    18,   715,  1263,   171,   211,    18,\n",
              "         829,    20,    27,  3807,     4,   214,   121,  1212,   153,\n",
              "       13004,    31,  2765,  1847,    16, 13003, 13002,   754,     7,\n",
              "        3806,    99,  2430,   466,    31])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xH_4-1aGUw3e",
        "colab": {}
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c7Y5-orQU9AT",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GH3PzaWqU9EE",
        "colab": {}
      },
      "source": [
        "seq_length = x.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eMOwFF1wU9Tq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OQ60OEpYVCK7"
      },
      "source": [
        "LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sj3BZPAjU9Wj",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6iLcdyNZVGST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9cfe03fd-e7c8-46d0-bfc3-bb977bfcf21d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            650450    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 13009)             1313909   \n",
            "=================================================================\n",
            "Total params: 2,115,259\n",
            "Trainable params: 2,115,259\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VWA4Lfe7VGY0",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eql46haHVGeT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba8daf41-eef9-4a95-b863-0ca5df826496"
      },
      "source": [
        "model.fit(x, y, batch_size = 256, epochs=60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "782/782 [==============================] - 385s 492ms/step - loss: 6.8824 - accuracy: 0.0311\n",
            "Epoch 2/60\n",
            "782/782 [==============================] - 385s 493ms/step - loss: 6.5203 - accuracy: 0.0442\n",
            "Epoch 3/60\n",
            "782/782 [==============================] - 384s 491ms/step - loss: 6.3072 - accuracy: 0.0604\n",
            "Epoch 4/60\n",
            "782/782 [==============================] - 385s 492ms/step - loss: 6.1663 - accuracy: 0.0685\n",
            "Epoch 5/60\n",
            "782/782 [==============================] - 383s 489ms/step - loss: 6.0353 - accuracy: 0.0769\n",
            "Epoch 6/60\n",
            "782/782 [==============================] - 379s 484ms/step - loss: 5.9252 - accuracy: 0.0859\n",
            "Epoch 7/60\n",
            "782/782 [==============================] - 384s 492ms/step - loss: 5.8137 - accuracy: 0.0959\n",
            "Epoch 8/60\n",
            "782/782 [==============================] - 383s 490ms/step - loss: 5.7170 - accuracy: 0.1016\n",
            "Epoch 9/60\n",
            "782/782 [==============================] - 383s 490ms/step - loss: 5.6305 - accuracy: 0.1055\n",
            "Epoch 10/60\n",
            "782/782 [==============================] - 385s 492ms/step - loss: 5.5452 - accuracy: 0.1088\n",
            "Epoch 11/60\n",
            "782/782 [==============================] - 385s 492ms/step - loss: 5.4589 - accuracy: 0.1119\n",
            "Epoch 12/60\n",
            "782/782 [==============================] - 383s 490ms/step - loss: 5.3749 - accuracy: 0.1148\n",
            "Epoch 13/60\n",
            "782/782 [==============================] - 386s 494ms/step - loss: 5.2920 - accuracy: 0.1182\n",
            "Epoch 14/60\n",
            "782/782 [==============================] - 388s 496ms/step - loss: 5.2115 - accuracy: 0.1211\n",
            "Epoch 15/60\n",
            "782/782 [==============================] - 392s 502ms/step - loss: 5.1377 - accuracy: 0.1237\n",
            "Epoch 16/60\n",
            "782/782 [==============================] - 389s 497ms/step - loss: 5.0704 - accuracy: 0.1252\n",
            "Epoch 17/60\n",
            "782/782 [==============================] - 385s 492ms/step - loss: 4.9871 - accuracy: 0.1283\n",
            "Epoch 18/60\n",
            "782/782 [==============================] - 400s 512ms/step - loss: 4.9158 - accuracy: 0.1308\n",
            "Epoch 19/60\n",
            "782/782 [==============================] - 395s 505ms/step - loss: 4.8478 - accuracy: 0.1338\n",
            "Epoch 20/60\n",
            "782/782 [==============================] - 386s 494ms/step - loss: 4.7823 - accuracy: 0.1379\n",
            "Epoch 21/60\n",
            "782/782 [==============================] - 386s 494ms/step - loss: 4.7215 - accuracy: 0.1425\n",
            "Epoch 22/60\n",
            "782/782 [==============================] - 392s 501ms/step - loss: 4.6658 - accuracy: 0.1473\n",
            "Epoch 23/60\n",
            "782/782 [==============================] - 397s 508ms/step - loss: 4.6142 - accuracy: 0.1522\n",
            "Epoch 24/60\n",
            "782/782 [==============================] - 393s 502ms/step - loss: 4.5699 - accuracy: 0.1555\n",
            "Epoch 25/60\n",
            "782/782 [==============================] - 393s 502ms/step - loss: 4.5166 - accuracy: 0.1612\n",
            "Epoch 26/60\n",
            "782/782 [==============================] - 394s 503ms/step - loss: 4.4717 - accuracy: 0.1657\n",
            "Epoch 27/60\n",
            "782/782 [==============================] - 388s 496ms/step - loss: 4.4326 - accuracy: 0.1710\n",
            "Epoch 28/60\n",
            "782/782 [==============================] - 397s 508ms/step - loss: 4.3909 - accuracy: 0.1752\n",
            "Epoch 29/60\n",
            "782/782 [==============================] - 394s 503ms/step - loss: 4.3526 - accuracy: 0.1791\n",
            "Epoch 30/60\n",
            "782/782 [==============================] - 401s 513ms/step - loss: 4.3164 - accuracy: 0.1831\n",
            "Epoch 31/60\n",
            "782/782 [==============================] - 393s 503ms/step - loss: 4.2815 - accuracy: 0.1867\n",
            "Epoch 32/60\n",
            "782/782 [==============================] - 396s 506ms/step - loss: 4.2484 - accuracy: 0.1904\n",
            "Epoch 33/60\n",
            "782/782 [==============================] - 402s 514ms/step - loss: 4.2148 - accuracy: 0.1945\n",
            "Epoch 34/60\n",
            "782/782 [==============================] - 401s 512ms/step - loss: 4.1839 - accuracy: 0.1978\n",
            "Epoch 35/60\n",
            "782/782 [==============================] - 403s 515ms/step - loss: 4.1533 - accuracy: 0.2012\n",
            "Epoch 36/60\n",
            "782/782 [==============================] - 412s 527ms/step - loss: 4.1219 - accuracy: 0.2051\n",
            "Epoch 37/60\n",
            "782/782 [==============================] - 408s 522ms/step - loss: 4.0915 - accuracy: 0.2096\n",
            "Epoch 38/60\n",
            "782/782 [==============================] - 402s 514ms/step - loss: 4.0641 - accuracy: 0.2124\n",
            "Epoch 39/60\n",
            "782/782 [==============================] - 413s 528ms/step - loss: 4.0331 - accuracy: 0.2158\n",
            "Epoch 40/60\n",
            "782/782 [==============================] - 405s 518ms/step - loss: 4.0072 - accuracy: 0.2185\n",
            "Epoch 41/60\n",
            "782/782 [==============================] - 408s 521ms/step - loss: 3.9783 - accuracy: 0.2225\n",
            "Epoch 42/60\n",
            "782/782 [==============================] - 415s 531ms/step - loss: 3.9513 - accuracy: 0.2252\n",
            "Epoch 43/60\n",
            "782/782 [==============================] - 421s 538ms/step - loss: 3.9246 - accuracy: 0.2286\n",
            "Epoch 44/60\n",
            "782/782 [==============================] - 419s 535ms/step - loss: 3.8996 - accuracy: 0.2324\n",
            "Epoch 45/60\n",
            "782/782 [==============================] - 410s 524ms/step - loss: 3.8759 - accuracy: 0.2359\n",
            "Epoch 46/60\n",
            "782/782 [==============================] - 405s 517ms/step - loss: 3.8482 - accuracy: 0.2392\n",
            "Epoch 47/60\n",
            "782/782 [==============================] - 422s 540ms/step - loss: 3.8255 - accuracy: 0.2414\n",
            "Epoch 48/60\n",
            "782/782 [==============================] - 433s 553ms/step - loss: 3.8016 - accuracy: 0.2447\n",
            "Epoch 49/60\n",
            "782/782 [==============================] - 420s 538ms/step - loss: 3.7765 - accuracy: 0.2483\n",
            "Epoch 50/60\n",
            "782/782 [==============================] - 426s 545ms/step - loss: 3.7546 - accuracy: 0.2509\n",
            "Epoch 51/60\n",
            "782/782 [==============================] - 415s 530ms/step - loss: 3.7323 - accuracy: 0.2537\n",
            "Epoch 52/60\n",
            "782/782 [==============================] - 417s 533ms/step - loss: 3.7091 - accuracy: 0.2570\n",
            "Epoch 53/60\n",
            "782/782 [==============================] - 416s 532ms/step - loss: 3.6850 - accuracy: 0.2596\n",
            "Epoch 54/60\n",
            "782/782 [==============================] - 425s 543ms/step - loss: 3.6644 - accuracy: 0.2635\n",
            "Epoch 55/60\n",
            "782/782 [==============================] - 420s 537ms/step - loss: 3.6430 - accuracy: 0.2658\n",
            "Epoch 56/60\n",
            "782/782 [==============================] - 423s 541ms/step - loss: 3.6219 - accuracy: 0.2687\n",
            "Epoch 57/60\n",
            "782/782 [==============================] - 418s 534ms/step - loss: 3.6013 - accuracy: 0.2713\n",
            "Epoch 58/60\n",
            "782/782 [==============================] - 418s 535ms/step - loss: 3.5773 - accuracy: 0.2749\n",
            "Epoch 59/60\n",
            "782/782 [==============================] - 421s 539ms/step - loss: 3.5566 - accuracy: 0.2783\n",
            "Epoch 60/60\n",
            "782/782 [==============================] - 414s 529ms/step - loss: 3.5379 - accuracy: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd785074e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zvQ2k1MsVPDo",
        "colab": {}
      },
      "source": [
        "seed_text=lines[12343]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tn8b_aRFVPRI",
        "colab": {}
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "    text = []\n",
        "    \n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "        \n",
        "        y_predict = model.predict_classes(encoded)\n",
        "        \n",
        "        predicted_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == y_predict:\n",
        "                predicted_word = word\n",
        "                break\n",
        "        seed_text = seed_text + ' ' + predicted_word\n",
        "        text.append(predicted_word)\n",
        "    return ' '.join(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dm6ZHRkrVUI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9d0cec9-a661-46a5-d42a-c1cf9c10f157"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'preposterously be stained to make me to the future court'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8AGTQHahVUWg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2ae42a48-1e2f-43c0-a219-af0f2df0c591"
      },
      "source": [
        "seed_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'home of love if i have ranged like him that travels i return again just to the time not with the time exchanged so that my self bring water for my stain never believe though in my nature reigned all frailties that besiege all kinds of blood that it could so'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qmhgrVXW3vSh",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}